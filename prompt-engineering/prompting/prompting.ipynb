{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd8230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7790cf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99afb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0d4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
    "\n",
    "prompt = \"\"\"continue the followin story. Write no more than 50 words. Once upon a time, in a world where animals could speak, a courageous mouse named Benjamin decided to\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb85f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "messages =[\n",
    "    {\"role\": \"system\", \"content\": prompt_system},\n",
    "    {\"role\":\"user\", \"content\":prompt}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71fea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embark on a journey to save his village from a menacing hawk. Armed with quick wits and a heart full of determination, Benjamin set out into the unknown.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef831588",
   "metadata": {},
   "source": [
    "answer changes even with a single spelling mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd21205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'travel to the farthest reaches of the forest to seek out the legendary wise owl. With determination in his heart, Benjamin embarked on his journey, unaware of the challenges that awaited him.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
    "\n",
    "# here i have given courageous as courageious\n",
    "prompt = \"\"\"continue the followin story. Write no more than 50 words. Once upon a time, in a world where animals could speak, a courageious mouse named Benjamin decided to\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "messages =[\n",
    "    {\"role\": \"system\", \"content\": prompt_system},\n",
    "    {\"role\":\"user\", \"content\":prompt}\n",
    "])\n",
    "\n",
    "response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b9a48",
   "metadata": {},
   "source": [
    "### Product Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0830131d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Indulge in the ultimate writing experience with our exquisite limited-edition fountain pen. Handcrafted from lustrous rosewood and accented with luxurious gold, this pen exudes elegance and sophistication. Elevate your writing to new heights with this unique masterpiece.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to help write a product description.\"\n",
    "\n",
    "# here i have given courageous as courageious\n",
    "prompt = \"\"\"write a captivating product description for a luxurious, handcrafted, limited-edition fountain pen made from rosewood and gold. Write no more than 50 words\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "messages =[\n",
    "    {\"role\": \"system\", \"content\": prompt_system},\n",
    "    {\"role\":\"user\", \"content\":prompt}\n",
    "])\n",
    "\n",
    "response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb45ff",
   "metadata": {},
   "source": [
    "how does llm understand the word limit and generate only so much?<br>\n",
    "how does it keep track of it's word generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3fecc",
   "metadata": {},
   "source": [
    "<b> Language models are the offspring of the sum of all human linguistic output </b>\n",
    "- https://generative.ink/posts/methods-of-prompt-programming/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a55d369",
   "metadata": {},
   "source": [
    "## Prompting Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7590d",
   "metadata": {},
   "source": [
    "### Zero shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84f9d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
    "\n",
    "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": prompt_system,\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": prompt.format(topic=\"summer\")\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f31079e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden sunshine fills the skies,\n",
      "Warm breezes kiss my skin,\n",
      "Days stretch out with no goodbyes,\n",
      "In summer's sweet embrace we spin.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd3c83c",
   "metadata": {},
   "source": [
    "### 2. In-Context Learning And Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0718ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icy breath in the air,\n",
      "Frost dusts the world with care,\n",
      "Winter's chill, nature's flair.\n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
    "\n",
    "prompt = \"\"\"Write a short poem about {topic}\"\"\"\n",
    "\n",
    "examples = {\n",
    "    \"nature\": \"\"\"Birdsong fills the air, \\nMountains high and valleys deep,\\nNature's music sweet\"\"\",\n",
    "    \"winter\": \"\"\"Snow blankets the ground,\\n Silence is the only sound, \\nWinter's beauy found.\"\"\"\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "model = \"gpt-3.5-turbo\",\n",
    "messages = [\n",
    "    { \"role\": \"system\", \"content\": prompt_system},\n",
    "    {\"role\": \"user\", \"content\": prompt.format(topic=\"nature\")},\n",
    "    {\"role\": \"assistant\", \"content\": examples[\"nature\"]},\n",
    "    {\"role\": \"user\", \"content\": prompt.format(topic=\"winter\")},\n",
    "    {\"role\": \"assistant\", \"content\": examples[\"winter\"]},\n",
    "    {\"role\": \"user\", \"content\": prompt.format(topic=\"winter\")},\n",
    "])\n",
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4cad89",
   "metadata": {},
   "source": [
    "#### Few-Shot Prompting\n",
    "using langchain framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5edfadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2d1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\"color\":\"red\", \"emotion\":\"passion\"},\n",
    "    {\"color\":\"blue\", \"emotion\":\"serenity\"},\n",
    "    {\"color\":\"green\", \"emotion\":\"tranquility\"}\n",
    "]\n",
    "\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"color\", \"emotion\"],\n",
    "                               template=example_formatter_template,)\n",
    "\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "examples = examples,\n",
    "example_prompt=example_prompt,\n",
    "prefix = \"\"\"Here are some examples of colors and the emotions associated with them:\\n\\n\"\"\",\n",
    "suffix=\"\"\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor:{input}\\nEmotion:\"\"\",\n",
    "input_variables=[\"input\"],\n",
    "example_separator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d01727e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: brown\n",
      "Emotion:  earthiness\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = few_shot_prompt.format(input=\"brown\")\n",
    "\n",
    "# Creating thee LLMChain for the prompt\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "\n",
    "# Running LLM chain \n",
    "\n",
    "response = chain.run({})\n",
    "\n",
    "print(\"Color: brown\")\n",
    "print(\"Emotion: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46f42d",
   "metadata": {},
   "source": [
    "### Role Prompting\n",
    "Defining role in prompt , helping the llm to assume a specific role. helps it to tailor the outputs w.r.t those roles. shows how training on large data it can create its own alter-ego.\n",
    "1. papers regarding role prompting?\n",
    "2. role of temperature and how it works behind the scene?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed68f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "Ai generated song title:  \"Galactic Odyssey: Journey to the Stars\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(input_variables=[\"theme\", \"year\"], \n",
    "                      template=template\n",
    "                      )\n",
    "\n",
    "\n",
    "\n",
    "input_data = {\"theme\": \"Interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "\n",
    "# Creating LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"Ai generated song title: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e210a",
   "metadata": {},
   "source": [
    "What makes a good prompt?\n",
    "1. Precise Direction - making sure it gets what need to be genrated\n",
    "2. specificity - providing proper specific instruction like a conductor in a band\n",
    "3. Promoting Creativity - not giving specific format or style helping for creativity \n",
    "4. Concentrated on the task - concentrates exclusive on the task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476bb88",
   "metadata": {},
   "source": [
    "### Chain Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09b346f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist Albert Einstein\n",
      "Fact: Albert Einstein's theory of general relativity is a theory of gravitation that describes the force of gravity as a curvature of spacetime caused by mass and energy. According to this theory, massive objects like planets and stars warp the fabric of spacetime, causing other objects to move along curved paths. General relativity also predicts the existence of phenomena such as black holes, gravitational waves, and the bending of light around massive objects.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "#Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer = \"\"\"\n",
    "prompt_question =PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "\n",
    "#Prompt 2 \n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_fact = PromptTemplate(template=template_fact, input_variables=['scientist'])\n",
    "\n",
    "\n",
    "\n",
    "# creating the chain for first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLM of 1st prompt\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "\n",
    "# extracting scienstist name\n",
    "scientist = response_question.strip()\n",
    "\n",
    "chain_answer = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "input_data = { \"scientist\" : scientist }\n",
    "response_fact = chain_answer.run(input_data)\n",
    "\n",
    "print(\"Scientist\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66349a",
   "metadata": {},
   "source": [
    "### Chain of Thought Prompting\n",
    "Method designed to prompt LLM to articulate their thoughts process, to enhance the results. It's like mentoring and helping a junior to reach results by directing their thought process with reasoning.\n",
    "\n",
    "<i>Advantages of using Cot in langchain.</i>\n",
    "1. simplifies complex tasks by enabling to breakdown the challenging tasks which is valuable for tasks requiring calculations, logical analysis, or multi-step reasoning.\n",
    "2. it can guide the model through a series of related prompts, fostering more coherent and contextually appropriate outputs.\n",
    "\n",
    "<i> Limitations</i>\n",
    "1. helpful with large model i.e. 100 Billion parameters and above\n",
    "2. It's effectiveness can vary across different types of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a837b0d",
   "metadata": {},
   "source": [
    "#### Tips for effective Prompt Engineering\n",
    "* Be specific\n",
    "* Force conciseness\n",
    "* Encourage the model to describe why it is the way it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3232cf67",
   "metadata": {},
   "source": [
    "Examples of good prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e8ae3d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response: Practice active listening, be clear and concise in your communication, and work on empathizing with others to understand their perspective better.\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"what's the secret to the happiness?\",\n",
    "        \"answer\": \"\"\"Finding balance in life and learning to enjoy the small moments.\"\"\"\n",
    "    },{\n",
    "        \"query\": \"How can i become more productive?\",\n",
    "        \"answer\":\"\"\"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "Ai : {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "input_variables = [\"query\", \"answer\"],\n",
    "template=example_template\n",
    ")\n",
    "\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from the conversations with an AI life coach. \n",
    "The assistant provides insightful and practical advice to the user's questions. Here are some examples:\n",
    "\"\"\"\n",
    "\n",
    "# what will happen if i add a new lines after colon . what kind of response can be generated?\n",
    "suffix = \"\"\"\n",
    "User : {query},\n",
    "AI :\"\"\"\n",
    "\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "examples = examples,\n",
    "example_prompt=example_prompt,\n",
    "prefix = prefix,\n",
    "suffix=suffix,\n",
    "input_variables=[\"query\"],\n",
    "example_separator=\"\\n\\n\")\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edb1da3",
   "metadata": {},
   "source": [
    "1. what is 696x87?\n",
    "2. what is 696x87? \n",
    "<br>Let's think step by step encouraging the model to explain its reasoning leads to more accurate results.\n",
    "this doesn't give always correct answers so giving some context before (few shot prompting) helps model imitate the methodology to produce answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338a58e",
   "metadata": {},
   "source": [
    "here in this example\n",
    "* sets a clear context in the prefix\n",
    "* Utilizes Examples\n",
    "* Distinguishes Between Examples and Actual Query\n",
    "* Includes a Clear Suffix for User Input and AI Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9527f",
   "metadata": {},
   "source": [
    "## Zero shot Prompting\n",
    "1. direct task specifications \n",
    "2. proxy task specification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e3d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
