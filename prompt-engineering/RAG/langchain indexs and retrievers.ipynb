{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6650ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9f71be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "# text to write a local file\n",
    "\n",
    "\n",
    "\n",
    "#taken from https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai\n",
    "\n",
    "\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3 / The search giant is launching an API for its large language model PaLM. Businesses and developers will be able to build on the system to create custom chatbots and much more.\n",
    "By James Vincent, a senior reporter who has covered AI, robotics, and more for eight years at The Verge.\n",
    "\n",
    "Google logo with colorful shapes\n",
    "Illustration: The Verge\n",
    "Google is offering developers access to one of its most advanced AI language models: PaLM. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs, PaLM is a flexible system that can potentially carry out all sorts of text generation and editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for example, or you could use it for tasks like summarizing text or even writing code. (It’s similar to features Google also announced today for its Workspace apps like Google Docs and Gmail.)\n",
    "\n",
    "In order to make it easier for developers to train PaLM to carry out specific tasks, Google is launching a new app alongside the PaLM API called MakerSuite. “With MakerSuite, you’ll be able to iterate on prompts, augment your dataset with synthetic data, and easily tune custom models,” said the company in a press release. Google says this sort of fine-tuning, which is necessary to create a consumer-friendly AI system, can even be done in a browser, with the computationally intensive work of training and deployment handled by Google Cloud.\n",
    "\n",
    "In addition to launching the PaLM API, Google is also expanding support for generative AI in its Vertex AI platform, which is designed to help businesses train and deploy machine learning models. It says Vertex will have access to more models built by Google Research and its AI subsidiary DeepMind and will also be able to tap into open-source and third-party systems in the future.\n",
    "\n",
    "And finally, Google is also launching a new platform called Generative AI App Builder. The company says this platform “allows developers to quickly ship new experiences including bots, chat interfaces, custom search engines, digital assistants, and more. Developers have API access to Google’s foundation models and can use out-of-the-box templates to jumpstart the creation of gen apps in minutes or hours.”\n",
    "\n",
    "All of this may sound a bit dry and enterprise-focused — and it is! — but it’s also a big push by Google to put more AI tools in the hands of more companies. Specifically, access to PaLM will give businesses the opportunity to build new AI language services the same way OpenAI’s language APIs led to an explosion of startups. In other words, the PaLM API is another engine that will fuel new AI developments in 2023.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open(\"my_file.txt\", \"w\") as file:\n",
    "    file.write(text)\n",
    "    \n",
    "    \n",
    "loader = TextLoader(\"my_file.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d2a6e",
   "metadata": {},
   "source": [
    "#### characterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1e6505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 354, which is longer than the specified 200\n",
      "Created a chunk of size 357, which is longer than the specified 200\n",
      "Created a chunk of size 541, which is longer than the specified 200\n",
      "Created a chunk of size 544, which is longer than the specified 200\n",
      "Created a chunk of size 383, which is longer than the specified 200\n",
      "Created a chunk of size 408, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "print(len(docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad88b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f1821c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 7 embeddings in 1 batches of size 7:: 100%|█████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://Ali/lanchain_course_indexers_retrievers', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (7, 1)      str     None   \n",
      " metadata     json      (7, 1)      str     None   \n",
      " embedding  embedding  (7, 1536)  float32   None   \n",
      "    id        text      (7, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6ee448e0-3c92-11ef-8bda-36ea86592e58',\n",
       " '6ee44afc-3c92-11ef-8bda-36ea86592e58',\n",
       " '6ee44b38-3c92-11ef-8bda-36ea86592e58',\n",
       " '6ee44b60-3c92-11ef-8bda-36ea86592e58',\n",
       " '6ee44b7e-3c92-11ef-8bda-36ea86592e58',\n",
       " '6ee44ba6-3c92-11ef-8bda-36ea86592e58',\n",
       " '6ee44bce-3c92-11ef-8bda-36ea86592e58']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "my_activeloop_ord_id = \"Ali\"\n",
    "my_activeloop_dataset_name = \"lanchain_course_indexers_retrievers\"\n",
    "\n",
    "\n",
    "dataset_path = f\"hub://{my_activeloop_ord_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d207fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retriever from db\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d1d2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# text the author about this issue\n",
    "\n",
    "# create a retrieval chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "chain_type=\"stuff\",\n",
    "retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee655563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google plans to challenge OpenAI by opening up its AI language model PaLM through an API. This will allow businesses and developers to build custom chatbots and other applications using the system. Additionally, Google is launching a platform called Generative AI App Builder, which will enable developers to quickly create new experiences such as bots, chat interfaces, digital assistants, and more. By providing access to PaLM and expanding support for generative AI in its Vertex AI platform, Google aims to put more AI tools in the hands of companies and fuel new AI developments in 2023.\n"
     ]
    }
   ],
   "source": [
    "query = \"How Google plans to challenge OpenAI?\"\n",
    "response = qa_chain.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1023c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
